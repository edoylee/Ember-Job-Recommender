{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethandoyle/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from predictNew import PreprocessData, Predict, ScrapeGlass, LinkedinScraper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dups(train, test):\n",
    "    train_df = pd.read_csv(train, index_col=0)\n",
    "    test_df = pd.read_csv(test, index_col=0)\n",
    "    final_jobs = test_df.copy()\n",
    "    for test_job in test_df.jobs.values:\n",
    "        for train_job in train_df.jobs.values:\n",
    "            if test_job == train_job:\n",
    "                final_jobs.drop(index=final_jobs[final_jobs.jobs == test_job].index[0], inplace=True)\n",
    "    return final_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_jobs = remove_dups('data/GLASSTEST.csv', 'data/HOTTEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>companies</th>\n",
       "      <th>jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Scientist, Formulations, Viral Vector Process ...</td>\n",
       "      <td>4.0 ★Juno Therapeutics– Seattle, WA, United St...</td>\n",
       "      <td>Juno is seeking an enthusiastic, self-driven i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>3.9 ★Versive– Seattle, WA</td>\n",
       "      <td>The Role:\\n\\nAt Versive, we want to cut throug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>4.5 ★PagerDuty– Seattle</td>\n",
       "      <td>At PagerDuty, we believe that people do their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.5 ★H10 Capital– Seattle, WA</td>\n",
       "      <td>Job Description\\nOur Telecommunications client...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>2.7 ★Rakuten– Seattle</td>\n",
       "      <td>We are looking for an experienced data scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Siri - Data Scientist (Machine Learning &amp; Natu...</td>\n",
       "      <td>4.0 ★Apple– Seattle, Washington</td>\n",
       "      <td>Summary\\nPlay a part in the ongoing revolution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>3.8 ★Amazon– Seattle, WA</td>\n",
       "      <td>Job Description\\nDo you want to build a cuttin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               titles  \\\n",
       "5   Scientist, Formulations, Viral Vector Process ...   \n",
       "6                          Machine Learning Scientist   \n",
       "7                                    Data Scientist I   \n",
       "8                                      Data Scientist   \n",
       "9                                      Data Scientist   \n",
       "10  Siri - Data Scientist (Machine Learning & Natu...   \n",
       "11                                      Data Engineer   \n",
       "\n",
       "                                            companies  \\\n",
       "5   4.0 ★Juno Therapeutics– Seattle, WA, United St...   \n",
       "6                           3.9 ★Versive– Seattle, WA   \n",
       "7                             4.5 ★PagerDuty– Seattle   \n",
       "8                       4.5 ★H10 Capital– Seattle, WA   \n",
       "9                               2.7 ★Rakuten– Seattle   \n",
       "10                    4.0 ★Apple– Seattle, Washington   \n",
       "11                           3.8 ★Amazon– Seattle, WA   \n",
       "\n",
       "                                                 jobs  \n",
       "5   Juno is seeking an enthusiastic, self-driven i...  \n",
       "6   The Role:\\n\\nAt Versive, we want to cut throug...  \n",
       "7   At PagerDuty, we believe that people do their ...  \n",
       "8   Job Description\\nOur Telecommunications client...  \n",
       "9   We are looking for an experienced data scienti...  \n",
       "10  Summary\\nPlay a part in the ongoing revolution...  \n",
       "11  Job Description\\nDo you want to build a cuttin...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PreprocessData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = data.transform('data/GLASSTEST.csv', 'data/ETHANTEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indices</th>\n",
       "      <th>titles</th>\n",
       "      <th>companies</th>\n",
       "      <th>jobs</th>\n",
       "      <th>labels</th>\n",
       "      <th>distances</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>1300</th>\n",
       "      <th>1301</th>\n",
       "      <th>1302</th>\n",
       "      <th>1303</th>\n",
       "      <th>1304</th>\n",
       "      <th>1305</th>\n",
       "      <th>1306</th>\n",
       "      <th>1307</th>\n",
       "      <th>1308</th>\n",
       "      <th>1309</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist with an economics background fr...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.6 ★Tableau Software– Seattle, Washington</td>\n",
       "      <td>**What youll be doing**The primary focus of th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.861950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036914</td>\n",
       "      <td>0.066963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>5.0 ★Suplari– Seattle, WA</td>\n",
       "      <td>Our mission at Suplari is to shine the light o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.8 ★Amazon– Seattle, WA</td>\n",
       "      <td>Job Description\\nThe Amazon Demand Forecasting...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.899140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>3.8 ★Expedia– Bellevue, Washington</td>\n",
       "      <td>Expedia\\n\\nWho we are\\n\\neCP Expedia eCommerce...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.902016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Scientist, Sr.</td>\n",
       "      <td>3.7 ★Seattle Children's Hospital– Seattle, WA</td>\n",
       "      <td>Join our Bioinformatics Delivery Team! Using t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>Data Scientist - Verticals</td>\n",
       "      <td>4.2 ★Uber– Seattle, Washington, United States</td>\n",
       "      <td>At Uber, we ignite opportunity by setting the ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.1 ★EagleView Technologies– Bellevue, WA</td>\n",
       "      <td>We are looking for talented Data Scientists to...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.926140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>4.1 ★ExtraHop Networks, Inc.– Seattle, WA, Uni...</td>\n",
       "      <td>The ExtraHop platform is a novel approach to p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932524</td>\n",
       "      <td>0.043019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.6 ★TIBCO Software– Seattle, WA, US</td>\n",
       "      <td>Our Data Science team are central to our globa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist - Risk</td>\n",
       "      <td>3.3 ★Postmates Inc.– Bellevue, WA</td>\n",
       "      <td>Postmates runs one of the largest marketplaces...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 1316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    indices                      titles  \\\n",
       "0         0                         NaN   \n",
       "1         2              Data Scientist   \n",
       "2         8       Senior Data Scientist   \n",
       "3         1              Data Scientist   \n",
       "4         5            Data Scientist I   \n",
       "5         3         Data Scientist, Sr.   \n",
       "6         9  Data Scientist - Verticals   \n",
       "7         6              Data Scientist   \n",
       "8        10    Associate Data Scientist   \n",
       "9         7              Data Scientist   \n",
       "10        4       Data Scientist - Risk   \n",
       "\n",
       "                                            companies  \\\n",
       "0                                                 NaN   \n",
       "1          3.6 ★Tableau Software– Seattle, Washington   \n",
       "2                           5.0 ★Suplari– Seattle, WA   \n",
       "3                            3.8 ★Amazon– Seattle, WA   \n",
       "4                  3.8 ★Expedia– Bellevue, Washington   \n",
       "5       3.7 ★Seattle Children's Hospital– Seattle, WA   \n",
       "6       4.2 ★Uber– Seattle, Washington, United States   \n",
       "7           3.1 ★EagleView Technologies– Bellevue, WA   \n",
       "8   4.1 ★ExtraHop Networks, Inc.– Seattle, WA, Uni...   \n",
       "9                3.6 ★TIBCO Software– Seattle, WA, US   \n",
       "10                  3.3 ★Postmates Inc.– Bellevue, WA   \n",
       "\n",
       "                                                 jobs  labels  distances  \\\n",
       "0   Data Scientist with an economics background fr...    10.0   0.000000   \n",
       "1   **What youll be doing**The primary focus of th...     0.0   0.861950   \n",
       "2   Our mission at Suplari is to shine the light o...     0.0   0.871546   \n",
       "3   Job Description\\nThe Amazon Demand Forecasting...     0.0   0.899140   \n",
       "4   Expedia\\n\\nWho we are\\n\\neCP Expedia eCommerce...     0.0   0.902016   \n",
       "5   Join our Bioinformatics Delivery Team! Using t...     0.0   0.911966   \n",
       "6   At Uber, we ignite opportunity by setting the ...     0.0   0.917575   \n",
       "7   We are looking for talented Data Scientists to...     0.0   0.926140   \n",
       "8   The ExtraHop platform is a novel approach to p...     0.0   0.932524   \n",
       "9   Our Data Science team are central to our globa...     0.0   0.934063   \n",
       "10  Postmates runs one of the largest marketplaces...     0.0   0.937161   \n",
       "\n",
       "           0         1         2         3    ...         1300      1301  \\\n",
       "0   0.000000  0.000000  0.000000  0.000000    ...     0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  0.066963    ...     0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  0.000000    ...     0.000000  0.000000   \n",
       "3   0.000000  0.042778  0.042778  0.000000    ...     0.000000  0.042778   \n",
       "4   0.000000  0.000000  0.000000  0.000000    ...     0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.000000  0.000000    ...     0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  0.000000    ...     0.114174  0.000000   \n",
       "7   0.000000  0.000000  0.000000  0.000000    ...     0.000000  0.000000   \n",
       "8   0.043019  0.000000  0.000000  0.000000    ...     0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  0.000000    ...     0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  0.000000    ...     0.000000  0.000000   \n",
       "\n",
       "        1302      1303      1304      1305      1306      1307      1308  \\\n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.036914  0.066963  0.000000   \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.026564  0.000000  0.000000   \n",
       "3   0.042778  0.042778  0.000000  0.000000  0.047164  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  0.043292  0.000000  0.000000  0.043292   \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.084110  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.031470  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.043019  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.071334  0.000000  0.000000   \n",
       "\n",
       "        1309  \n",
       "0   0.061251  \n",
       "1   0.000000  \n",
       "2   0.000000  \n",
       "3   0.000000  \n",
       "4   0.000000  \n",
       "5   0.000000  \n",
       "6   0.000000  \n",
       "7   0.000000  \n",
       "8   0.000000  \n",
       "9   0.000000  \n",
       "10  0.000000  \n",
       "\n",
       "[11 rows x 1316 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
